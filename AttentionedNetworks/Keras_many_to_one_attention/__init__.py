"""
Many to one attention on RNN for keras

Seems just a little better than the implementation in keras_attention_layer_for_classification

https://github.com/philipperemy/keras-attention-mechanism

25000/25000 [==============================] - 161s 6ms/sample - loss: 0.1518 - acc: 0.9443 - val_loss: 0.3231 - val_acc: 0.8716

"""